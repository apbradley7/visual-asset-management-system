#  Copyright 2023 Amazon.com, Inc. or its affiliates. All Rights Reserved.
#  SPDX-License-Identifier: Apache-2.0

import os
import boto3
import json
import botocore
import base64
import io
from utils.rekognition import RekognitionImage
from utils.rekognition import RekognitionLabel
from utils.rekognition import RekognitionText
from customLogging.logger import safeLogger

logger = safeLogger(service="MetadataGenerationPipeline")

s3_client = boto3.client('s3')
s3_resource = boto3.resource('s3')
rekognition_client = boto3.client('rekognition')
bedrock_client = boto3.client('bedrock-runtime')
max_tokens = 10000
metadataJsonPrimaryKey = "autoGeneratedKeywords"
metadataFileObjectName = "generatedMetadata.json"

def image_to_base64(img_path) -> str:
    with open(img_path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")

def get_all_image_files_in_path(bucket, path):

    result = {
        "Items": []
    }

    response = s3_client.list_objects(Bucket=bucket, Prefix=path)
    if 'Contents' in response:
        # map object from object list
        keys = []
        for o in response["Contents"]:
            if o['Key'].endswith('.png'):
                result["Items"].append({
                    'key': o['Key'],
                    'relativePath': o['Key'].removeprefix(path)
                })

    # Log the length of files with a description
    logger.info("Files in the path: ")
    logger.info(len(result["Items"]))
    return result["Items"]


def invoke_claude_3_with_text(prompt, base64_image_data = None):
    """
    Invokes Anthropic Claude 3 Sonnet to run an inference using the input
    provided in the request body.

    :param prompt: The prompt that you want Claude 3 to complete along with the image.
    :return: Inference response from the model.
    """

    # Invoke Claude 3 with the text + image prompt
    model_id = "anthropic.claude-3-sonnet-20240229-v1:0"

    body = ""
    if base64_image_data:
        body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": max_tokens,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        },
                        {
                            "type": "image",
                            "source": {
                                "type": "base64",
                                "media_type": "image/png",
                                "data": base64_image_data,
                            },
                        },
                        ],
                }
            ],
        }
    else:
        body = {
            "anthropic_version": "bedrock-2023-05-31",
            "max_tokens": max_tokens,
            "messages": [
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": prompt
                        }
                        ],
                }
            ],
        }

    try:
        response = bedrock_client.invoke_model(
            modelId=model_id,
            body=json.dumps(body),
        )

        # Process and print the response
        result = json.loads(response.get("body").read())
        input_tokens = result["usage"]["input_tokens"]
        output_tokens = result["usage"]["output_tokens"]
        output_list = result.get("content", [])

        logger.info("Invocation details:")
        logger.info(f"- The input length is {input_tokens} tokens.")
        logger.info(f"- The output length is {output_tokens} tokens.")

        logger.info(f"- The model returned {len(output_list)} response(s):")
        for output in output_list:
            logger.info(output["text"])

        return result

    except botocore.exceptions.ClientError as err:
        logger.exception("Couldn't invoke Bedrock LLM.")
        logger.exception(err)
        raise


#Define a recursive function to take in a dict and recursive down all the dict field, convert the field value to a str, and add it to an array
#Exclude previously generated metadataJsonPrimaryKey from the metadata as it could skew results and further possible hallucinations.
def dict_to_str_array(d):
    arr = []
    for k, v in d.items():
        if(str(k) != metadataJsonPrimaryKey):
            if isinstance(v, dict):
                arr.extend(dict_to_str_array(v))
            elif isinstance(v, list):
                if len(v) > 0:
                    arr.append(str(k)+":::"+(','.join(v)))
            else:
                if str(v) != "":
                    arr.append(str(k)+":::"+str(v))
    return arr

def lambda_handler(event, context):
    """
    Metadata Generation Pipeline Lambda Handler
    Handle processing of GenAI metadata extraction, metadata saving, and cleanup
    """

    logger.info(f"Event Input: {event}")
    logger.info(f"Context Input: {context}")

    #TODO: Try/catch

    pipelineDefinitions = json.loads(event['definition'][0])
    pipelineStageDefinition = {}

    #TODO: use container code as a layer to provide better definition ingestion / responsing
    foundStage = False
    for stage in pipelineDefinitions['stages']:
        if stage['type'] == 'METADATAGENERATION':
            pipelineStageDefinition = stage
            foundStage = True
            break

    if foundStage == False:
        logger.error("No metadata generation stage found in pipeline definition.")
        raise Exception("No metadata generation stage found in pipeline definition.")
    
    #Get and parse input parameters
    inputParameters = event.get("inputParameters", "")
    inputParametersObject = {}
    if(isinstance(inputParameters,str) and inputParameters != ""):
        try:
            inputParametersObject = json.loads(inputParameters)
        except:
            logger.error("Input parameters is not valid JSON.")

    #Get and parse input metadata
    inputMetadata = event.get("inputMetadata", "")
    inputMetadataObject = {}
    if(isinstance(inputMetadata,str) and inputMetadata != ""):
        try:
            inputMetadataObject = json.loads(inputMetadata)
        except:
            logger.error("Input metadata is not valid JSON.")

    #Get input/output locations
    inputBucket = pipelineStageDefinition['inputFile']['bucketName']
    inputKeyDir = pipelineStageDefinition['inputFile']['objectDir']
    outputTempBucket = pipelineStageDefinition['temporaryFiles']['bucketName']
    outputTempKeyDir = pipelineStageDefinition['temporaryFiles']['objectDir']
    outputMetadataBucket = pipelineStageDefinition['outputMetadata'].get("bucketName", "")
    outputMetadataKeyDir = pipelineStageDefinition['outputMetadata'].get("objectDir", "")

    #Get input parameters
    seedMetadataGenerationWithInputMetadata = inputParametersObject.get("seedMetadataGenerationWithInputMetadata", "False")

    #Input Metadata Fields to Aggregate for use from Various Called Systems
    inputMetadataFieldsToAggregate = []
    if seedMetadataGenerationWithInputMetadata == "True":
        inputMetadataFieldsToAggregate = dict_to_str_array(inputMetadataObject)


    #Get all S3 image paths at input bucket directory location
    imagePaths = get_all_image_files_in_path(bucket=inputBucket, path=inputKeyDir)

    #Error if no images returned
    if len(imagePaths) == 0:
        logger.error("No images found in the input directory.")
        raise Exception("No images found in the input directory.")

    #Prompt text
    promptImage = "You are given an image of a single camera view from a set of rendered images of a 3D object. \
        Describe to me the scene and objects in the image with only a comma-deliminated set of labels that match a confidence score of 97% or greater. \
        If the image provided is blank, has no objects in it besides a basic background color, has objects that are too small, has a bad camera angle of the object, or has unreconigzable objects, then return the single keyword of 'none'. \
        Error on the side of high confidence when choosing labels as multiple images will be evaluated and the aggregate of the labels will be used. "
    
    if len(inputMetadataFieldsToAggregate) > 0:
        logger.info("Input Metadata Fields Used: "+str(';'.join(inputMetadataFieldsToAggregate)))
        promptImage = promptImage + f"Use the provided semicolon-deliminated key-value metadata elements to help further curate the labels identified from the rendered image and reduce outliers. \
          These provided metadata elements are pre-associations that users have saved in the system with the 3D object. \
          Each provided key-value pair elements will be in the form of 'key:::value'. \
          The metadata elements are: '''{';'.join(inputMetadataFieldsToAggregate)}'''"

    promptImage = promptImage + ". Again, Skip the preamble and ONLY return the list of comma deliminated labels or 'none'"

    returnText = ""

    # Path to store images files in temporary storage
    logger.info("S3 Image paths to process:")
    for imagePath in imagePaths:
        logger.info(imagePath)
        tmp_image_path = '/tmp/' + imagePath['relativePath']
        s3_client.download_file(inputBucket, imagePath['key'], tmp_image_path) 
        image_base64 = image_to_base64(tmp_image_path)

        #Call claude 
        claude_result = invoke_claude_3_with_text(promptImage, image_base64)
        claudResultText = claude_result.get('content')[0].get('text')
        if claudResultText != "none":
            returnText = returnText + claudResultText + "," 
            logger.info("Claude Returned Keywords: "+claudResultText)
        else:
            logger.info("Claude Returned Keywords: none")

        #Call rekognition
        rekognition_image = RekognitionImage.from_file(
            tmp_image_path, rekognition_client
        )

        #get labels
        labels = rekognition_image.detect_labels(30)
        logger.info(f"Found {len(labels)} labels by rekognition total (all confidences).")
        for label in labels:
            try:
                if float(label.confidence) > 97:
                    logger.info("Label found within confidence:" + label.name)
                    returnText = returnText + label.name + ","
            except Exception as e:
                logger.info("Rekognition Error. Could not parse label.")

        #todo: get text from images too?
        
        #Remove tempoary images
        if os.path.exists(tmp_image_path):
            os.remove(tmp_image_path)

    #Final claude summary
    promptFinalSummarization = "Task: Consolidate a list of image labels into a JSON object with the following criteria: \
                                Deduplication: Remove duplicate keywords, regardless of case. (e.g., 'Red Car' and 'red car' should be treated as the same). \
                                Outlier Analysis: Identify and remove keywords that appear infrequently compared to the overall set. You can implement a threshold filter and do sentiment analysis. For example, remove keywords that appear less than 10% of the time. (This threshold can be adjusted based on the expected data distribution).\
                                Casing: Convert all keywords to lowercase unless it is a acronym like 'CAD'. \
                                Seed Metadata Integration: (Optional) If provided, use a separate list of seed keywords, phrases, or descriptions as metadata to help refine the final list of image label keywords. These seed keywords could describe the overall theme or category of the image collection. Do not automatically add these seed keywords to the final output. Only keywords that appear in the image label inputs should be the set used for the output. \
                                ONLY output at the end the final JSON object with no other preamble or explanation.\
                                Inputs:\
                                image_labels: A list of strings representing the labels assigned to each image.\
                                seed_keywords (Optional): A list of strings representing additional metadata keywords describing the image collection.\
                                Output:\
                                A JSON object with a single key '"+metadataJsonPrimaryKey+"' containing a list of filtered and deduplicated string keywords.\
                                Example Input/Output:\
                                example_image_labels = ['red car', 'blue car', 'red truck', 'tree', 'Red Car'] \
                                example_seed_keywords = ['vehicle']\
                                example_output: {'"+metadataJsonPrimaryKey+"': ['red car', 'red truck', 'blue car']}\
                                Final Input:\
                                image_labels: " + returnText + "\
                                seed_keywords: "
    
    if len(inputMetadataFieldsToAggregate) > 0:
            logger.info("Input Metadata Fields Used: "+str(';'.join(inputMetadataFieldsToAggregate)))
            promptFinalSummarization = promptFinalSummarization

    # promptFinalSummarization = "Consolidate and summarize the bottom list of provided keywords into a new list of unique keywords. \
    # Compare all the keywords and remove all outlier keywords from the list based on frequency and term category. An example of an outlier would be 'pottery' or 'ashtray' in a keyword list where most other keywords are describing a electronic object. \
    # Keywords are not case sensitive and should be compared for uniqueness across casings. "

    # if len(inputMetadataFieldsToAggregate) > 0:
    #     logger.info("Input Metadata Fields Used: "+str(';'.join(inputMetadataFieldsToAggregate)))
    #     promptFinalSummarization = promptFinalSummarization + f"Additionally use this provided list of semicolon-deliminated key-value metadata elements to help further curate the labels identified from the rendered image and reduce outliers. \
    #       These provided metadata elements are pre-associations that users have saved in the system with the 3D object. \
    #       Each provided key-value pair elements will be in the form of 'key:::value'. \
    #       The metadata elements are: '''{';'.join(inputMetadataFieldsToAggregate)}'''"

    # promptFinalSummarization = promptFinalSummarization + "Format the keywords into a JSON data object with a '"+metadataJsonPrimaryKey+"' array field and respond ONLY with that JSON formatted data object: " + returnText

    claude_result = invoke_claude_3_with_text(promptFinalSummarization)
    finalText = claude_result.get('content')[0].get('text') 
    logger.info(returnText)

    #Save list of keywords back to S3 output directory in a JSON text file in S3 Temporary Bucket
    outputTempKey = outputTempKeyDir + metadataFileObjectName
    s3_client.put_object(Body=finalText, Bucket=outputTempBucket, Key=outputTempKey)

    #Save list of keywords back to S3 output directory in a JSON text file in S3 Metadata Bucket (if bucket provided)
    if(outputMetadataBucket):
        outputMetadataKey = outputMetadataKeyDir + metadataFileObjectName
        s3_client.put_object(Body=finalText, Bucket=outputMetadataBucket, Key=outputMetadataKey)

    return event
